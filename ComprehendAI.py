"""
ComprehendAI - IDA Pro AI åˆ†ææ’ä»¶
åŸºäº OpenAI API çš„æ™ºèƒ½é€†å‘å·¥ç¨‹åˆ†æå·¥å…·
"""
import traceback
import idaapi
import idc
import idautils
import ida_xref
import json
import os
from typing import Optional, Set, List

from idaapi import action_handler_t, UI_Hooks
from threading import Lock, Thread, Event
from openai import OpenAI
from enum import Enum


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    ANALYSIS = 1
    CUSTOM_QUERY = 2
    CUSTOM_QUERY_WITH_CODE = 3


class QueryStatus(Enum):
    """æŸ¥è¯¢çŠ¶æ€æšä¸¾"""
    SUCCESS = 1
    FAILED = 2
    STOPPED = 3

# é…ç½®æ–‡ä»¶åç§°å¸¸é‡
CONFIG_FILENAME = 'config.json'
DEFAULT_MAX_DEPTH = 2
DEFAULT_ANALYSIS_DEPTH = 2


class ConfigManager:
    """
    é…ç½®ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼
    è´Ÿè´£åŠ è½½é…ç½®æ–‡ä»¶å’Œåˆ›å»º OpenAI å®¢æˆ·ç«¯
    """
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        with cls._lock:
            if not cls._instance:
                cls._instance = super().__new__(cls)
                cls._instance._initialize()
            return cls._instance
    
    def _initialize(self):
        """åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨"""
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.config_path = os.path.join(self.script_dir, CONFIG_FILENAME)
        self.config = self._load_config()
        self.openai_client = self._create_openai_client()
        
    def _load_config(self) -> dict:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Returns:
            dict: é…ç½®å­—å…¸
            
        Raises:
            RuntimeError: é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥
        """
        try:
            if not os.path.exists(self.config_path):
                raise FileNotFoundError(
                    f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}\n"
                    f"è¯·å‚è€ƒ config_sample.json åˆ›å»º config.json"
                )
            
            with open(self.config_path, "r", encoding="utf-8") as f:
                config = json.load(f)
                
            # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
            if "openai" not in config:
                raise KeyError("é…ç½®æ–‡ä»¶ç¼ºå°‘ 'openai' é…ç½®é¡¹")
            
            required_keys = ["api_key", "base_url", "model"]
            for key in required_keys:
                if key not in config["openai"]:
                    raise KeyError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘ 'openai.{key}' é…ç½®é¡¹")
                    
            return config
            
        except FileNotFoundError as e:
            raise RuntimeError(str(e))
        except json.JSONDecodeError as e:
            raise RuntimeError(f"é…ç½®æ–‡ä»¶ JSON æ ¼å¼é”™è¯¯: {str(e)}")
        except Exception as e:
            raise RuntimeError(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _create_openai_client(self) -> OpenAI:
        """
        åˆ›å»º OpenAI å®¢æˆ·ç«¯
        
        Returns:
            OpenAI: OpenAI å®¢æˆ·ç«¯å®ä¾‹
        """
        return OpenAI(
            api_key=self.config["openai"]["api_key"],
            base_url=self.config["openai"]["base_url"]
        )
    
    @property
    def model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        return self.config["openai"]["model"]
    
    @property
    def client(self) -> OpenAI:
        """è·å– OpenAI å®¢æˆ·ç«¯"""
        return self.openai_client
class DisassemblyProcessor:
    """
    åæ±‡ç¼–ä»£ç æå–å¤„ç†å™¨
    è´Ÿè´£æå–å½“å‰å‡½æ•°åŠå…¶è°ƒç”¨çš„å­å‡½æ•°çš„åç¼–è¯‘ä»£ç 
    """
    
    def __init__(self, max_depth: int = DEFAULT_MAX_DEPTH):
        """
        åˆå§‹åŒ–åæ±‡ç¼–å¤„ç†å™¨
        
        Args:
            max_depth: æœ€å¤§åˆ†ææ·±åº¦,æ§åˆ¶é€’å½’æå–å­å‡½æ•°çš„å±‚æ•°
        """
        self.max_depth = max_depth
        self._lock = Lock()
        self._reset_state()
        
    def _reset_state(self):
        """é‡ç½®å¤„ç†çŠ¶æ€"""
        with self._lock:
            self.processed_funcs: Set[int] = set()
            self.func_disasm_list: List[str] = []
    
    def get_current_function_disasm(self) -> str:
        """
        è·å–å½“å‰å…‰æ ‡ä½ç½®å‡½æ•°çš„åç¼–è¯‘ä»£ç åŠå…¶å­å‡½æ•°
        
        Returns:
            str: åç¼–è¯‘ä»£ç å­—ç¬¦ä¸²
            
        Raises:
            ValueError: æ— æ³•å®šä½å‡½æ•°èµ·å§‹åœ°å€
        """
        self._reset_state()
        
        current_ea = idc.get_screen_ea()
        func_start = idc.get_func_attr(current_ea, idc.FUNCATTR_START)
        
        if func_start == idaapi.BADADDR:
            raise ValueError("æ— æ³•å®šä½å‡½æ•°èµ·å§‹åœ°å€,è¯·ç¡®ä¿å…‰æ ‡ä½äºæœ‰æ•ˆå‡½æ•°å†…")
            
        self._process_function(func_start, self.max_depth)
        
        if not self.func_disasm_list:
            raise ValueError("æœªèƒ½æå–åˆ°ä»»ä½•åç¼–è¯‘ä»£ç ")
            
        return "\n\n" + "=" * 80 + "\n\n".join(self.func_disasm_list)
    
    def _process_function(self, func_ea: int, depth: int):
        """
        é€’å½’å¤„ç†å‡½æ•°åŠå…¶è°ƒç”¨çš„å­å‡½æ•°
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            depth: å½“å‰å‰©ä½™é€’å½’æ·±åº¦
        """
        if func_ea in self.processed_funcs or depth < 0:
            return
            
        with self._lock:
            self.processed_funcs.add(func_ea)
        
        try:
            # å°è¯•åç¼–è¯‘å‡½æ•°
            decompiled = str(idaapi.decompile(func_ea))
            func_name = idc.get_func_name(func_ea)
            
            # æ·»åŠ å‡½æ•°æ ‡è¯†ä¿¡æ¯
            header = f"\n{'=' * 80}\nå‡½æ•°: {func_name} (åœ°å€: {hex(func_ea)})\n{'=' * 80}\n"
            
            with self._lock:
                self.func_disasm_list.append(header + decompiled)
                
        except Exception as e:
            print(f"âŒ åç¼–è¯‘å¤±è´¥ {hex(func_ea)}: {str(e)}")
            return
        
        # é€’å½’å¤„ç†å­å‡½æ•°
        if depth > 0:
            for callee in self._get_callees(func_ea):
                self._process_function(callee, depth - 1)
    
    def _get_callees(self, func_ea: int) -> Set[int]:
        """
        è·å–å‡½æ•°è°ƒç”¨çš„æ‰€æœ‰å­å‡½æ•°åœ°å€
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            
        Returns:
            Set[int]: å­å‡½æ•°åœ°å€é›†åˆ
        """
        callees = set()
        func_end = idc.get_func_attr(func_ea, idc.FUNCATTR_END)
        
        if func_end == idaapi.BADADDR:
            return callees
            
        for ea in range(func_ea, func_end):
            for xref in idautils.XrefsFrom(ea):
                # åªå¤„ç†å‡½æ•°è°ƒç”¨ç±»å‹çš„äº¤å‰å¼•ç”¨
                if xref.type in [ida_xref.fl_CN, ida_xref.fl_CF]:
                    callee_ea = xref.to
                    # ç¡®è®¤æ˜¯å‡½æ•°èµ·å§‹åœ°å€
                    if idc.get_func_attr(callee_ea, idc.FUNCATTR_START) == callee_ea:
                        callees.add(callee_ea)
        return callees
class AIService:
    """
    AI æœåŠ¡ç±»
    è´Ÿè´£ä¸ OpenAI API äº¤äº’,å¤„ç†åˆ†æè¯·æ±‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ– AI æœåŠ¡"""
        self.config = ConfigManager()
        self.stop_event = Event()

    def ask_ai(self, prompt: str, ai_isRunning: Lock):
        """
        å‘ AI æå‡ºé—®é¢˜
        
        Args:
            prompt: æç¤ºè¯
            ai_isRunning: è¿è¡ŒçŠ¶æ€é”
        """
        messages = [{"role": "user", "content": prompt}]
        print("\n" + "=" * 80)
        print("ComprehendAI è¾“å‡º:")
        print("=" * 80 + "\n")
        
        self.stop_event.clear()  # åˆå§‹åŒ–åœæ­¢äº‹ä»¶
        
        try:
            result = self._request_openai(messages)
        finally:
            # ç¡®ä¿æ— è®ºæˆåŠŸå¤±è´¥éƒ½é‡Šæ”¾é”
            ai_isRunning.release()

        # è¾“å‡ºæœ€ç»ˆçŠ¶æ€
        match result:
            case QueryStatus.SUCCESS:
                print("\n" + "=" * 80)
                print("âœ… åˆ†æå®Œæˆï¼")
                print("=" * 80)
            case QueryStatus.FAILED:
                print("\n" + "=" * 80)
                print("âŒ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®æˆ–ç½‘ç»œè¿æ¥")
                print("=" * 80)
            case QueryStatus.STOPPED:
                print("\n" + "=" * 80)
                print("â¸ï¸ åˆ†æå·²åœæ­¢")
                print("=" * 80)

    def _request_openai(self, messages: List[dict]) -> QueryStatus:
        """
        è¯·æ±‚ OpenAI API
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            QueryStatus: æŸ¥è¯¢çŠ¶æ€
        """
        reasoning_content = ""
        answer_content = ""
        is_answering = False
        
        try:
            completion = self.config.client.chat.completions.create(
                model=self.config.model_name,
                messages=messages,
                stream=True,
            )
            
            for chunk in completion:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.stop_event.is_set():
                    print("\n\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·,æ­£åœ¨ä¸­æ–­...")
                    return QueryStatus.STOPPED

                # å¤„ç† usage ä¿¡æ¯
                if not chunk.choices:
                    if hasattr(chunk, 'usage') and chunk.usage:
                        print(f"\n\nğŸ“Š Token ä½¿ç”¨æƒ…å†µ: {chunk.usage}")
                    continue
                
                delta = chunk.choices[0].delta
                
                # å¤„ç†æ¨ç†å†…å®¹(å¦‚æœæ¨¡å‹æ”¯æŒ)
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                    print(delta.reasoning_content, end='', flush=True)
                    reasoning_content += delta.reasoning_content
                
                # å¤„ç†å›å¤å†…å®¹
                elif delta.content is not None:
                    if not is_answering and delta.content:
                        print("\n" + "=" * 20 + " å®Œæ•´å›å¤ " + "=" * 20 + "\n")
                        is_answering = True
                    answer_content += delta.content
            
            # æ‰“å°å®Œæ•´å›å¤
            if answer_content:
                print(answer_content)
            else:
                print("âš ï¸ AI æœªè¿”å›æœ‰æ•ˆå†…å®¹")
                
            return QueryStatus.SUCCESS
        
        except StopIteration as e:
            print(f"\nâš ï¸ è¿­ä»£è¢«ä¸­æ–­: {e}")
            return QueryStatus.STOPPED

        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            if hasattr(e, '__class__'):
                print(f"é”™è¯¯ç±»å‹: {e.__class__.__name__}")
            traceback.print_exc()
            return QueryStatus.FAILED


# é»˜è®¤åˆ†ææç¤ºè¯æ¨¡æ¿
DEFAULT_ANALYSIS_PROMPT = """
ä½ æ˜¯ä¸€åäººå·¥æ™ºèƒ½é€†å‘å·¥ç¨‹ä¸“å®¶ã€‚
æˆ‘ä¼šæä¾›ä½ ä¸€äº›åæ±‡ç¼–ä»£ç ï¼Œå…¶ä¸­é¦–ä¸ªå‡½æ•°æ˜¯ä½ éœ€è¦åˆ†æå¹¶æ€»ç»“æˆæŠ¥å‘Šçš„å‡½æ•°ï¼Œ
å…¶ä½™å‡½æ•°æ˜¯è¯¥å‡½æ•°è°ƒç”¨çš„ä¸€äº›å­å‡½æ•°ã€‚

åˆ†æè¦æ±‚ï¼š
1. é‡ç‚¹æè¿°ä¸»å‡½æ•°åŠŸèƒ½ï¼Œå¹¶å¯¹æ ¸å¿ƒè¡Œä¸ºè¿›è¡Œæ¨æµ‹
2. ç®€è¦æè¿°å­å‡½æ•°åŠŸèƒ½
3. è¯†åˆ«æ½œåœ¨çš„å®‰å…¨é—®é¢˜æˆ–æ¼æ´
4. åˆ†æå‡½æ•°çš„å¤æ‚åº¦å’Œæ€§èƒ½ç‰¹ç‚¹

è¾“å‡ºè¦æ±‚ï¼š
ä¸»å‡½æ•°åŠŸèƒ½ï¼š...
æ ¸å¿ƒè¡Œä¸ºæ¨æµ‹ï¼š...
å­å‡½æ•°åŠŸèƒ½ï¼š...
å®‰å…¨æ€§åˆ†æï¼š...
å¤æ‚åº¦è¯„ä¼°ï¼š...

è¯·ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼è¾“å‡ºã€‚

ä¸‹é¢æ˜¯ä½ è¦åˆ†æçš„åæ±‡ç¼–ä»£ç ï¼š
"""


class AnalysisHandler:
    """
    åˆ†æå¤„ç†å™¨
    è´Ÿè´£åè°ƒåæ±‡ç¼–æå–å’Œ AI åˆ†æ
    """

    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå¤„ç†å™¨"""
        self.disassembler = DisassemblyProcessor()
        self.ai_service = AIService()
        self.ai_isRunning = Lock()
        self.prompt = DEFAULT_ANALYSIS_PROMPT
        
    def set_analysis_depth(self, depth: int):
        """
        è®¾ç½®åˆ†ææ·±åº¦
        
        Args:
            depth: åˆ†ææ·±åº¦(å­å‡½æ•°é€’å½’å±‚æ•°)
        """
        if depth < 0:
            print("âŒ åˆ†ææ·±åº¦å¿…é¡»å¤§äºç­‰äº 0")
            return
            
        self.disassembler.max_depth = depth
        print(f"âœ… åˆ†ææ·±åº¦å·²è®¾ç½®ä¸º: {depth}")
    
    def _create_analysis_prompt(self, disassembly: str) -> str:
        """
        åˆ›å»ºåˆ†ææç¤ºè¯
        
        Args:
            disassembly: åæ±‡ç¼–ä»£ç 
            
        Returns:
            str: å®Œæ•´æç¤ºè¯
        """
        return self.prompt + "\n" + disassembly
    
    def _create_custom_query_with_code(self, disassembly: str, question: str) -> str:
        """
        åˆ›å»ºå¸¦ä»£ç çš„è‡ªå®šä¹‰æŸ¥è¯¢
        
        Args:
            disassembly: åæ±‡ç¼–ä»£ç 
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: å®Œæ•´æç¤ºè¯
        """
        return f"{question}\n\nåæ±‡ç¼–ä»£ç :\n{disassembly}"
    
    def create_ai_task(self, task_type: TaskType, question: str = ""):
        """
        åˆ›å»º AI åˆ†æä»»åŠ¡
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            question: ç”¨æˆ·é—®é¢˜(ä»…éƒ¨åˆ†ä»»åŠ¡ç±»å‹éœ€è¦)
        """
        try:
            match task_type:
                case TaskType.ANALYSIS:
                    print("ğŸ“ æ­£åœ¨æå–åæ±‡ç¼–ä»£ç ...")
                    disassembly = self.disassembler.get_current_function_disasm()
                    prompt = self._create_analysis_prompt(disassembly)
                    self._async_task(prompt)
                    
                case TaskType.CUSTOM_QUERY:
                    if not question:
                        print("âŒ è¯·æä¾›é—®é¢˜å†…å®¹")
                        return
                    self._async_task(question)
                    
                case TaskType.CUSTOM_QUERY_WITH_CODE:
                    if not question:
                        print("âŒ è¯·æä¾›é—®é¢˜å†…å®¹")
                        return
                    print("ğŸ“ æ­£åœ¨æå–åæ±‡ç¼–ä»£ç ...")
                    disassembly = self.disassembler.get_current_function_disasm()
                    prompt = self._create_custom_query_with_code(disassembly, question)
                    self._async_task(prompt)
                    
        except ValueError as e:
            print(f"âŒ {str(e)}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")
            traceback.print_exc()
        
    def _async_task(self, prompt: str):
        """
        å¼‚æ­¥æ‰§è¡Œ AI ä»»åŠ¡
        
        Args:
            prompt: æç¤ºè¯
        """
        if self.ai_isRunning.acquire(blocking=False):
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ AI è¯·æ±‚
            task = Thread(
                target=self.ai_service.ask_ai,
                args=(prompt, self.ai_isRunning),
                daemon=True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
            )
            task.start()
            print("ğŸš€ AI ä»»åŠ¡å·²å¯åŠ¨...")
        else:
            print("âŒ å½“å‰ AI æ­£åœ¨å¤„ç†ä»»åŠ¡,è¯·ç¨åå°è¯•æˆ–ä½¿ç”¨ Stop åœæ­¢å½“å‰ä»»åŠ¡")
    
    def stop(self):
        """åœæ­¢å½“å‰ AI ä»»åŠ¡"""
        if self.ai_service.stop_event.is_set():
            print("â„¹ï¸ æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡")
        else:
            self.ai_service.stop_event.set()
            print("ğŸ›‘ æ­£åœ¨åœæ­¢ä»»åŠ¡...")

class ComprehendAIPlugin(idaapi.plugin_t):
    """
    ComprehendAI IDA Pro æ’ä»¶
    æä¾›åŸºäº AI çš„æ™ºèƒ½äºŒè¿›åˆ¶ä»£ç åˆ†æåŠŸèƒ½
    """
    
    flags = idaapi.PLUGIN_HIDE
    comment = "AI-based Reverse Analysis Plugin"
    help = "Perform AI-based analysis on binary code using OpenAI"
    wanted_name = "ComprehendAI"
    wanted_hotkey = "Ctrl+Shift+A"

    # æ’ä»¶åŠ¨ä½œå®šä¹‰ (action_id, æ˜¾ç¤ºåç§°, æç¤ºä¿¡æ¯)
    ACTION_DEFINITIONS = [
        ("AI_analysis:Analysis", "ğŸ¤– AI åˆ†æ", "æ‰§è¡Œ AI æ™ºèƒ½åˆ†æ"),
        ("AI_analysis:SetDepth", "âš™ï¸ è®¾ç½®åˆ†ææ·±åº¦", "è®¾ç½®å‡½æ•°åˆ†æçš„é€’å½’æ·±åº¦"),
        ("AI_analysis:SetPrompt", "ğŸ“ è‡ªå®šä¹‰æç¤ºè¯", "è‡ªå®šä¹‰åˆ†ææç¤ºè¯æ¨¡æ¿"),
        ("AI_analysis:CustomQueryWithCode", "ğŸ’¬ å¸¦ä»£ç æé—®", "ç»“åˆå½“å‰ä»£ç å‘ AI æé—®"),
        ("AI_analysis:CustomQuery", "ğŸ’­ ç›´æ¥æé—®", "ç›´æ¥å‘ AI æé—®"),
        ("AI_analysis:Stop", "ğŸ›‘ åœæ­¢", "åœæ­¢å½“å‰ AI ä»»åŠ¡"),
    ]

    def init(self):
        """
        åˆå§‹åŒ–æ’ä»¶
        
        Returns:
            int: PLUGIN_KEEP ä¿æŒæ’ä»¶åŠ è½½
        """
        try:
            # æ³¨å†Œ UI é’©å­
            self.ui_hook = self.MenuHook()
            self.ui_hook.hook()
            
            # åˆ›å»ºåˆ†æå¤„ç†å™¨
            self.handler = AnalysisHandler()
            
            # æ³¨å†Œæ‰€æœ‰åŠ¨ä½œ
            self._register_actions()
            
            print("=" * 80)
            print("âœ… ComprehendAI æ’ä»¶å·²æˆåŠŸåŠ è½½")
            print("=" * 80)
            return idaapi.PLUGIN_KEEP
            
        except Exception as e:
            print("=" * 80)
            print(f"âŒ ComprehendAI æ’ä»¶åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print("=" * 80)
            traceback.print_exc()
            return idaapi.PLUGIN_SKIP

    def run(self, arg):
        """
        è¿è¡Œæ’ä»¶(å½“å‰æœªä½¿ç”¨)
        
        Args:
            arg: æ’ä»¶å‚æ•°
        """
        pass

    def term(self):
        """å¸è½½æ’ä»¶"""
        try:
            self.ui_hook.unhook()
            self._unregister_actions()
            print("=" * 80)
            print("ğŸ‘‹ ComprehendAI æ’ä»¶å·²å¸è½½")
            print("=" * 80)
        except Exception as e:
            print(f"âŒ æ’ä»¶å¸è½½æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    def _register_actions(self):
        """æ³¨å†Œæ‰€æœ‰èœå•åŠ¨ä½œ"""
        for action_id, label, tooltip in self.ACTION_DEFINITIONS:
            action_desc = idaapi.action_desc_t(
                action_id,
                label,
                self.MenuCommandHandler(action_id, self.handler),
                None,
                tooltip,
                0
            )
            if not idaapi.register_action(action_desc):
                print(f"âš ï¸ æ³¨å†ŒåŠ¨ä½œå¤±è´¥: {action_id}")

    def _unregister_actions(self):
        """æ³¨é”€æ‰€æœ‰èœå•åŠ¨ä½œ"""
        for action_id, _, _ in self.ACTION_DEFINITIONS:
            idaapi.unregister_action(action_id)

    class MenuHook(UI_Hooks):
        """èœå•é’©å­,ç”¨äºåœ¨å³é”®èœå•ä¸­æ·»åŠ æ’ä»¶é€‰é¡¹"""
        
        def finish_populating_widget_popup(self, form, popup):
            """
            åœ¨çª—å£å¼¹å‡ºèœå•å®Œæˆå¡«å……æ—¶è°ƒç”¨
            
            Args:
                form: çª—å£å¥æŸ„
                popup: å¼¹å‡ºèœå•å¥æŸ„
            """
            widget_type = idaapi.get_widget_type(form)
            
            # åªåœ¨åæ±‡ç¼–è§†å›¾å’Œä¼ªä»£ç è§†å›¾ä¸­æ˜¾ç¤ºèœå•
            if widget_type in (idaapi.BWN_DISASM, idaapi.BWN_PSEUDOCODE):
                for action_id, _, _ in ComprehendAIPlugin.ACTION_DEFINITIONS:
                    idaapi.attach_action_to_popup(
                        form, 
                        popup, 
                        action_id, 
                        "ComprehendAI/", 
                        idaapi.SETMENU_APP
                    )

    class MenuCommandHandler(action_handler_t):
        """èœå•å‘½ä»¤å¤„ç†å™¨"""
        
        def __init__(self, action_id: str, handler: AnalysisHandler):
            """
            åˆå§‹åŒ–å‘½ä»¤å¤„ç†å™¨
            
            Args:
                action_id: åŠ¨ä½œ ID
                handler: åˆ†æå¤„ç†å™¨
            """
            super().__init__()
            self.action_id = action_id
            self.handler = handler
    
        def activate(self, ctx):
            """
            æ¿€æ´»åŠ¨ä½œ
            
            Args:
                ctx: ä¸Šä¸‹æ–‡
                
            Returns:
                int: 1 è¡¨ç¤ºæˆåŠŸ
            """
            try:
                match self.action_id:
                    case "AI_analysis:Analysis":
                        self.handler.create_ai_task(TaskType.ANALYSIS)
                        
                    case "AI_analysis:CustomQuery":
                        question = idaapi.ask_text(0, "", "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:")
                        if question:
                            self.handler.create_ai_task(TaskType.CUSTOM_QUERY, question)
                            
                    case "AI_analysis:SetDepth":
                        current_depth = self.handler.disassembler.max_depth
                        new_depth = idaapi.ask_long(
                            current_depth, 
                            f"è®¾ç½®åˆ†ææ·±åº¦ (å½“å‰: {current_depth}):"
                        )
                        if new_depth is not None:
                            self.handler.set_analysis_depth(new_depth)
                            
                    case "AI_analysis:SetPrompt":
                        new_prompt = idaapi.ask_text(
                            0, 
                            self.handler.prompt, 
                            "è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿:"
                        )
                        if new_prompt:
                            self.handler.prompt = new_prompt
                            print("âœ… æç¤ºè¯æ¨¡æ¿å·²æ›´æ–°")
                            
                    case "AI_analysis:CustomQueryWithCode":
                        question = idaapi.ask_text(
                            0, 
                            "", 
                            "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ (å°†ç»“åˆå½“å‰ä»£ç ):"
                        )
                        if question:
                            self.handler.create_ai_task(
                                TaskType.CUSTOM_QUERY_WITH_CODE, 
                                question
                            )
                            
                    case "AI_analysis:Stop":
                        self.handler.stop()
                        
            except Exception as e:
                print(f"âŒ æ‰§è¡Œæ“ä½œå¤±è´¥: {str(e)}")
                traceback.print_exc()
                
            return 1

        def update(self, ctx):
            """
            æ›´æ–°åŠ¨ä½œçŠ¶æ€
            
            Args:
                ctx: ä¸Šä¸‹æ–‡
                
            Returns:
                int: åŠ¨ä½œçŠ¶æ€
            """
            return idaapi.AST_ENABLE_ALWAYS


def PLUGIN_ENTRY():
    """
    IDA Pro æ’ä»¶å…¥å£ç‚¹
    
    Returns:
        ComprehendAIPlugin: æ’ä»¶å®ä¾‹
    """
    return ComprehendAIPlugin()