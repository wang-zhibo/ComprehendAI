"""
ComprehendAI - IDA Pro AI åˆ†ææ’ä»¶
åŸºäº OpenAI API çš„æ™ºèƒ½é€†å‘å·¥ç¨‹åˆ†æå·¥å…·

ä¼˜åŒ–ç‰ˆæœ¬ - åŒ…å«å¢å¼ºçš„æ—¥å¿—ã€é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–
"""
import traceback
import idaapi
import idc
import idautils
import ida_xref
import ida_bytes
import ida_nalt
import json
import os
import hashlib
import time
import logging
import sys
from datetime import datetime
from typing import Optional, Set, List, Dict, Tuple, Callable
from pathlib import Path
from functools import wraps

from idaapi import action_handler_t, UI_Hooks
from threading import Lock, Thread, Event
from openai import OpenAI
from enum import Enum


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    ANALYSIS = 1
    CUSTOM_QUERY = 2
    CUSTOM_QUERY_WITH_CODE = 3
    BATCH_ANALYSIS = 4  # æ‰¹é‡åˆ†æ
    SECURITY_AUDIT = 5  # å®‰å…¨å®¡è®¡
    VULNERABILITY_SCAN = 6  # æ¼æ´æ‰«æ


class QueryStatus(Enum):
    """æŸ¥è¯¢çŠ¶æ€æšä¸¾"""
    SUCCESS = 1
    FAILED = 2
    STOPPED = 3


# é…ç½®æ–‡ä»¶åç§°å¸¸é‡
CONFIG_FILENAME = 'config.json'
DEFAULT_MAX_DEPTH = 2
DEFAULT_ANALYSIS_DEPTH = 2
CACHE_DIR = 'comprehendai_cache'
EXPORT_DIR = 'comprehendai_exports'
LOG_DIR = 'comprehendai_logs'
MAX_CACHE_SIZE = 100  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
DEFAULT_REQUEST_TIMEOUT = 300  # é»˜è®¤è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_RETRY_COUNT = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°


class Logger:
    """
    ç»Ÿä¸€æ—¥å¿—ç®¡ç†å™¨
    æä¾›æ ¼å¼åŒ–çš„æ—¥å¿—è¾“å‡ºå’Œæ–‡ä»¶è®°å½•
    """
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        with cls._lock:
            if not cls._instance:
                cls._instance = super().__new__(cls)
                cls._instance._initialize()
            return cls._instance
    
    def _initialize(self):
        """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ"""
        script_dir = Path(__file__).parent
        log_dir = script_dir / LOG_DIR
        log_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        log_file = log_dir / f"comprehendai_{datetime.now().strftime('%Y%m%d')}.log"
        
        # é…ç½®æ—¥å¿—æ ¼å¼
        self.logger = logging.getLogger('ComprehendAI')
        self.logger.setLevel(logging.DEBUG)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨ï¼ˆIDA è¾“å‡ºçª—å£ï¼‰
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter('%(message)s')
        console_handler.setFormatter(console_formatter)
        
        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
        if not self.logger.handlers:
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
    
    def info(self, msg: str, emoji: str = "â„¹ï¸"):
        """ä¿¡æ¯æ—¥å¿—"""
        self.logger.info(f"{emoji} {msg}")
    
    def success(self, msg: str):
        """æˆåŠŸæ—¥å¿—"""
        self.logger.info(f"âœ… {msg}")
    
    def warning(self, msg: str):
        """è­¦å‘Šæ—¥å¿—"""
        self.logger.warning(f"âš ï¸ {msg}")
    
    def error(self, msg: str, exc_info=False):
        """é”™è¯¯æ—¥å¿—"""
        self.logger.error(f"âŒ {msg}", exc_info=exc_info)
    
    def debug(self, msg: str):
        """è°ƒè¯•æ—¥å¿—"""
        self.logger.debug(f"ğŸ” {msg}")
    
    def section(self, title: str, char: str = "=", width: int = 80):
        """è¾“å‡ºåˆ†éš”åŒºåŸŸ"""
        self.logger.info(f"\n{char * width}")
        self.logger.info(f"{title}")
        self.logger.info(f"{char * width}\n")


def retry_on_failure(max_retries: int = MAX_RETRY_COUNT, delay: float = 1.0):
    """
    é‡è¯•è£…é¥°å™¨ - ç”¨äºAPIè°ƒç”¨å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    """
    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            logger = Logger()
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        logger.warning(f"æ“ä½œå¤±è´¥ï¼Œ{delay}ç§’åé‡è¯• ({attempt + 1}/{max_retries}): {str(e)}")
                        time.sleep(delay)
                    else:
                        logger.error(f"é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥: {str(e)}")
            
            raise last_exception
        return wrapper
    return decorator


def safe_execute(default_return=None, log_error: bool = True):
    """
    å®‰å…¨æ‰§è¡Œè£…é¥°å™¨ - æ•è·å¼‚å¸¸å¹¶è¿”å›é»˜è®¤å€¼
    
    Args:
        default_return: å‘ç”Ÿå¼‚å¸¸æ—¶çš„é»˜è®¤è¿”å›å€¼
        log_error: æ˜¯å¦è®°å½•é”™è¯¯æ—¥å¿—
    """
    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if log_error:
                    logger = Logger()
                    logger.error(f"{func.__name__} æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
                return default_return
        return wrapper
    return decorator


class ConfigManager:
    """
    é…ç½®ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼
    è´Ÿè´£åŠ è½½é…ç½®æ–‡ä»¶å’Œåˆ›å»º OpenAI å®¢æˆ·ç«¯
    """
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        with cls._lock:
            if not cls._instance:
                cls._instance = super().__new__(cls)
                cls._instance._initialize()
            return cls._instance
    
    def _initialize(self):
        """åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨"""
        self.logger = Logger()
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.config_path = os.path.join(self.script_dir, CONFIG_FILENAME)
        self.config = self._load_config()
        self.openai_client = self._create_openai_client()
        
    def _load_config(self) -> dict:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Returns:
            dict: é…ç½®å­—å…¸
            
        Raises:
            RuntimeError: é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥
        """
        try:
            if not os.path.exists(self.config_path):
                error_msg = (
                    f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}\n"
                    f"è¯·å‚è€ƒ config_sample.json åˆ›å»º config.json"
                )
                self.logger.error(error_msg)
                raise FileNotFoundError(error_msg)
            
            with open(self.config_path, "r", encoding="utf-8") as f:
                config = json.load(f)
            
            # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
            if "openai" not in config:
                raise KeyError("é…ç½®æ–‡ä»¶ç¼ºå°‘ 'openai' é…ç½®é¡¹")
            
            required_keys = ["api_key", "base_url", "model"]
            for key in required_keys:
                if key not in config["openai"]:
                    raise KeyError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘ 'openai.{key}' é…ç½®é¡¹")
            
            self.logger.debug(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            self.logger.debug(f"ä½¿ç”¨æ¨¡å‹: {config['openai']['model']}")
            
            return config
            
        except FileNotFoundError as e:
            raise RuntimeError(str(e))
        except json.JSONDecodeError as e:
            error_msg = f"é…ç½®æ–‡ä»¶ JSON æ ¼å¼é”™è¯¯: {str(e)}"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)
        except Exception as e:
            error_msg = f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise RuntimeError(error_msg)
    
    def _create_openai_client(self) -> OpenAI:
        """
        åˆ›å»º OpenAI å®¢æˆ·ç«¯
        
        Returns:
            OpenAI: OpenAI å®¢æˆ·ç«¯å®ä¾‹
        """
        try:
            client = OpenAI(
                api_key=self.config["openai"]["api_key"],
                base_url=self.config["openai"]["base_url"],
                timeout=self.config["openai"].get("timeout", DEFAULT_REQUEST_TIMEOUT)
            )
            self.logger.debug("OpenAI å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            return client
        except Exception as e:
            self.logger.error(f"åˆ›å»º OpenAI å®¢æˆ·ç«¯å¤±è´¥: {str(e)}", exc_info=True)
            raise
    
    @property
    def model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        return self.config["openai"]["model"]
    
    @property
    def client(self) -> OpenAI:
        """è·å– OpenAI å®¢æˆ·ç«¯"""
        return self.openai_client
    
    @property
    def request_timeout(self) -> int:
        """è·å–è¯·æ±‚è¶…æ—¶æ—¶é—´"""
        return self.config["openai"].get("timeout", DEFAULT_REQUEST_TIMEOUT)
    
    @property
    def max_retries(self) -> int:
        """è·å–æœ€å¤§é‡è¯•æ¬¡æ•°"""
        return self.config.get("max_retries", MAX_RETRY_COUNT)


class CacheManager:
    """
    åˆ†æç»“æœç¼“å­˜ç®¡ç†å™¨
    ä½¿ç”¨å‡½æ•°åœ°å€å’Œä»£ç çš„å“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜é”®
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.logger = Logger()
        self.cache: Dict[str, Dict] = {}
        self._lock = Lock()
        self.cache_dir = self._get_cache_dir()
        self._load_cache()
    
    def _get_cache_dir(self) -> Path:
        """è·å–ç¼“å­˜ç›®å½•è·¯å¾„"""
        script_dir = Path(__file__).parent
        cache_dir = script_dir / CACHE_DIR
        cache_dir.mkdir(exist_ok=True)
        return cache_dir
    
    def _generate_cache_key(self, func_ea: int, code: str) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ - ä½¿ç”¨ SHA256ï¼‰
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            code: ä»£ç å†…å®¹
            
        Returns:
            str: ç¼“å­˜é”®ï¼ˆå“ˆå¸Œå€¼ï¼‰
        """
        # åªä½¿ç”¨ä»£ç å“ˆå¸Œï¼Œåœ°å€ä½œä¸ºå…ƒæ•°æ®å­˜å‚¨
        return hashlib.sha256(code.encode('utf-8')).hexdigest()
    
    @safe_execute(default_return=None, log_error=True)
    def get(self, func_ea: int, code: str) -> Optional[str]:
        """
        è·å–ç¼“å­˜çš„åˆ†æç»“æœ
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            code: ä»£ç å†…å®¹
            
        Returns:
            Optional[str]: ç¼“å­˜çš„ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        cache_key = self._generate_cache_key(func_ea, code)
        
        with self._lock:
            if cache_key in self.cache:
                cache_entry = self.cache[cache_key]
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ24å°æ—¶ï¼‰
                if time.time() - cache_entry['timestamp'] < 86400:
                    self.logger.info(f"ä½¿ç”¨ç¼“å­˜ç»“æœ (å‡½æ•°: {hex(func_ea)})", emoji="ğŸ“¦")
                    self.logger.debug(f"ç¼“å­˜é”®: {cache_key[:16]}...")
                    return cache_entry['result']
                else:
                    # åˆ é™¤è¿‡æœŸç¼“å­˜
                    del self.cache[cache_key]
                    self.logger.debug(f"åˆ é™¤è¿‡æœŸç¼“å­˜: {cache_key[:16]}...")
        
        return None
    
    @safe_execute(log_error=True)
    def set(self, func_ea: int, code: str, result: str):
        """
        ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            code: ä»£ç å†…å®¹
            result: åˆ†æç»“æœ
        """
        cache_key = self._generate_cache_key(func_ea, code)
        
        with self._lock:
            self.cache[cache_key] = {
                'func_ea': func_ea,
                'result': result,
                'timestamp': time.time()
            }
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.cache) > MAX_CACHE_SIZE:
                # åˆ é™¤æœ€æ—§çš„æ¡ç›®
                oldest_key = min(self.cache.keys(), 
                               key=lambda k: self.cache[k]['timestamp'])
                del self.cache[oldest_key]
                self.logger.debug(f"ç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§æ¡ç›®: {oldest_key[:16]}...")
            
            self.logger.debug(f"ä¿å­˜ç¼“å­˜: {cache_key[:16]}... (æ€»è®¡: {len(self.cache)} æ¡)")
        
        self._save_cache()
    
    @safe_execute(log_error=True)
    def _load_cache(self):
        """ä»æ–‡ä»¶åŠ è½½ç¼“å­˜"""
        cache_file = self.cache_dir / 'cache.json'
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                current_time = time.time()
                expired_keys = [
                    key for key, entry in self.cache.items()
                    if current_time - entry.get('timestamp', 0) >= 86400
                ]
                for key in expired_keys:
                    del self.cache[key]
                
                if expired_keys:
                    self.logger.info(f"æ¸…ç†äº† {len(expired_keys)} æ¡è¿‡æœŸç¼“å­˜", emoji="ğŸ§¹")
                
                self.logger.info(f"å·²åŠ è½½ {len(self.cache)} æ¡ç¼“å­˜è®°å½•", emoji="ğŸ“¦")
            except Exception as e:
                self.logger.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
                self.cache = {}
    
    @safe_execute(log_error=True)
    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        cache_file = self.cache_dir / 'cache.json'
        try:
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­æ€§å†™å…¥
            temp_file = cache_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
            temp_file.replace(cache_file)
        except Exception as e:
            self.logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        with self._lock:
            cache_count = len(self.cache)
            self.cache.clear()
        self._save_cache()
        self.logger.info(f"ç¼“å­˜å·²æ¸…ç©º (åˆ é™¤äº† {cache_count} æ¡è®°å½•)", emoji="ğŸ—‘ï¸")
    
    def get_stats(self) -> Dict[str, any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            total_size = sum(
                len(entry['result']) 
                for entry in self.cache.values()
            )
            return {
                'count': len(self.cache),
                'total_size_kb': total_size / 1024,
                'max_size': MAX_CACHE_SIZE
            }


class ContextExtractor:
    """
    ä»£ç ä¸Šä¸‹æ–‡æå–å™¨
    æå–å­—ç¬¦ä¸²ã€å¸¸é‡ã€å¯¼å…¥å‡½æ•°ç­‰é¢å¤–ä¿¡æ¯
    """
    
    @staticmethod
    def extract_strings(func_ea: int) -> List[str]:
        """
        æå–å‡½æ•°ä¸­çš„å­—ç¬¦ä¸²å¸¸é‡
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            
        Returns:
            List[str]: å­—ç¬¦ä¸²åˆ—è¡¨
        """
        strings = []
        func_end = idc.get_func_attr(func_ea, idc.FUNCATTR_END)
        
        if func_end == idaapi.BADADDR:
            return strings
        
        for ea in range(func_ea, func_end):
            # æ£€æŸ¥æ˜¯å¦æ˜¯å­—ç¬¦ä¸²å¼•ç”¨
            for xref in idautils.DataRefsFrom(ea):
                str_type = idc.get_str_type(xref)
                if str_type is not None:
                    s = idc.get_strlit_contents(xref)
                    if s:
                        try:
                            decoded = s.decode('utf-8', errors='ignore')
                            if decoded and decoded not in strings:
                                strings.append(decoded)
                        except:
                            pass
        
        return strings
    
    @staticmethod
    def extract_constants(func_ea: int) -> List[int]:
        """
        æå–å‡½æ•°ä¸­çš„æ•°å€¼å¸¸é‡
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            
        Returns:
            List[int]: å¸¸é‡åˆ—è¡¨
        """
        constants = set()
        func_end = idc.get_func_attr(func_ea, idc.FUNCATTR_END)
        
        if func_end == idaapi.BADADDR:
            return list(constants)
        
        for ea in range(func_ea, func_end):
            # æå–ç«‹å³æ•°
            insn = idautils.DecodeInstruction(ea)
            if insn:
                for op in insn.ops:
                    if op.type == idaapi.o_imm:
                        val = op.value
                        # è¿‡æ»¤æ‰å¤ªå°æˆ–å¤ªå¤§çš„å€¼
                        if 0 < val < 0x100000:
                            constants.add(val)
        
        return sorted(list(constants))[:20]  # é™åˆ¶è¿”å›æ•°é‡
    
    @staticmethod
    def get_function_info(func_ea: int) -> Dict[str, any]:
        """
        è·å–å‡½æ•°çš„åŸºæœ¬ä¿¡æ¯
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            
        Returns:
            Dict: å‡½æ•°ä¿¡æ¯å­—å…¸
        """
        func_name = idc.get_func_name(func_ea)
        func_start = idc.get_func_attr(func_ea, idc.FUNCATTR_START)
        func_end = idc.get_func_attr(func_ea, idc.FUNCATTR_END)
        
        info = {
            'name': func_name,
            'address': hex(func_ea),
            'start': hex(func_start) if func_start != idaapi.BADADDR else None,
            'end': hex(func_end) if func_end != idaapi.BADADDR else None,
            'size': func_end - func_start if func_end != idaapi.BADADDR else 0,
        }
        
        return info


class PromptTemplates:
    """é¢„è®¾æç¤ºè¯æ¨¡æ¿"""
    
    # æ ‡å‡†åˆ†ææ¨¡æ¿
    STANDARD_ANALYSIS = """
ä½ æ˜¯ä¸€åèµ„æ·±çš„é€†å‘å·¥ç¨‹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹åç¼–è¯‘ä»£ç ã€‚

åˆ†æè¦æ±‚ï¼š
1. æ¦‚è¿°ä¸»å‡½æ•°çš„æ ¸å¿ƒåŠŸèƒ½
2. è¯†åˆ«å…³é”®ç®—æ³•å’Œæ•°æ®ç»“æ„
3. åˆ†æå‡½æ•°çš„è¾“å…¥è¾“å‡º
4. ç®€è¦è¯´æ˜å­å‡½æ•°çš„ä½œç”¨

è¾“å‡ºæ ¼å¼ï¼š
**ä¸»å‡½æ•°åŠŸèƒ½**ï¼š
...

**å…³é”®é€»è¾‘**ï¼š
...

**å­å‡½æ•°è¯´æ˜**ï¼š
...

ä»£ç å¦‚ä¸‹ï¼š
"""
    
    # å®‰å…¨å®¡è®¡æ¨¡æ¿
    SECURITY_AUDIT = """
ä½ æ˜¯ä¸€åå®‰å…¨ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹ä»£ç è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚

å®¡è®¡é‡ç‚¹ï¼š
1. ç¼“å†²åŒºæº¢å‡ºé£é™©
2. æ•´æ•°æº¢å‡º/ä¸‹æº¢
3. ç©ºæŒ‡é’ˆè§£å¼•ç”¨
4. æœªåˆå§‹åŒ–å˜é‡ä½¿ç”¨
5. æ ¼å¼åŒ–å­—ç¬¦ä¸²æ¼æ´
6. ç«æ€æ¡ä»¶
7. ä¸å®‰å…¨çš„APIè°ƒç”¨

è¾“å‡ºæ ¼å¼ï¼š
**å®‰å…¨é£é™©ç­‰çº§**ï¼š[é«˜/ä¸­/ä½]

**å‘ç°çš„é—®é¢˜**ï¼š
1. ...
2. ...

**å»ºè®®ä¿®å¤æ–¹æ¡ˆ**ï¼š
...

ä»£ç å¦‚ä¸‹ï¼š
"""
    
    # æ¼æ´æ‰«ææ¨¡æ¿
    VULNERABILITY_SCAN = """
ä½ æ˜¯ä¸€åæ¼æ´æŒ–æ˜ä¸“å®¶ã€‚è¯·æ‰«æä»¥ä¸‹ä»£ç ä¸­å¯èƒ½å­˜åœ¨çš„å®‰å…¨æ¼æ´ã€‚

æ‰«æç›®æ ‡ï¼š
1. å¸¸è§CVEç±»å‹æ¼æ´
2. å†…å­˜å®‰å…¨é—®é¢˜
3. é€»è¾‘æ¼æ´
4. æƒé™ç»•è¿‡
5. æ³¨å…¥æ”»å‡»å‘é‡

è¾“å‡ºæ ¼å¼ï¼š
**æ¼æ´åˆ—è¡¨**ï¼š
1. [æ¼æ´ç±»å‹] - [å±å®³ç­‰çº§] - [ä½ç½®]
   æè¿°ï¼š...
   åˆ©ç”¨æ–¹å¼ï¼š...

**å¯åˆ©ç”¨æ€§è¯„ä¼°**ï¼š
...

ä»£ç å¦‚ä¸‹ï¼š
"""
    
    # ç®—æ³•è¯†åˆ«æ¨¡æ¿
    ALGORITHM_RECOGNITION = """
ä½ æ˜¯ä¸€åç®—æ³•ä¸“å®¶ã€‚è¯·è¯†åˆ«ä»¥ä¸‹ä»£ç ä¸­ä½¿ç”¨çš„ç®—æ³•ã€‚

è¯†åˆ«é‡ç‚¹ï¼š
1. åŠ å¯†/è§£å¯†ç®—æ³•ï¼ˆAES, RSA, DESç­‰ï¼‰
2. å“ˆå¸Œç®—æ³•ï¼ˆMD5, SHAç³»åˆ—ç­‰ï¼‰
3. å‹ç¼©ç®—æ³•
4. ç¼–ç ç®—æ³•ï¼ˆBase64, URLç¼–ç ç­‰ï¼‰
5. æ•°æ®ç»“æ„ç®—æ³•
6. è‡ªå®šä¹‰ç®—æ³•

è¾“å‡ºæ ¼å¼ï¼š
**è¯†åˆ«åˆ°çš„ç®—æ³•**ï¼š
1. ç®—æ³•åç§°ï¼š...
   ç®—æ³•ç±»å‹ï¼š...
   ç”¨é€”æ¨æµ‹ï¼š...

**ç®—æ³•ç‰¹å¾**ï¼š
...

ä»£ç å¦‚ä¸‹ï¼š
"""
    
    # å¿«é€Ÿæ€»ç»“æ¨¡æ¿
    QUICK_SUMMARY = """
è¯·ç”¨ç®€æ´çš„è¯­è¨€å¿«é€Ÿæ€»ç»“ä»¥ä¸‹å‡½æ•°çš„åŠŸèƒ½ï¼ˆä¸è¶…è¿‡3å¥è¯ï¼‰ï¼š

"""
    
    @classmethod
    def get_template(cls, template_name: str) -> str:
        """
        è·å–æŒ‡å®šçš„æ¨¡æ¿
        
        Args:
            template_name: æ¨¡æ¿åç§°
            
        Returns:
            str: æ¨¡æ¿å†…å®¹
        """
        return getattr(cls, template_name, cls.STANDARD_ANALYSIS)


class ResultExporter:
    """åˆ†æç»“æœå¯¼å‡ºå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¯¼å‡ºå™¨"""
        self.logger = Logger()
        self.export_dir = self._get_export_dir()
    
    def _get_export_dir(self) -> Path:
        """è·å–å¯¼å‡ºç›®å½•è·¯å¾„"""
        script_dir = Path(__file__).parent
        export_dir = script_dir / EXPORT_DIR
        export_dir.mkdir(exist_ok=True)
        return export_dir
    
    @safe_execute(default_return="", log_error=True)
    def export_result(self, func_name: str, func_addr: str, 
                     result: str, code: str = "") -> str:
        """
        å¯¼å‡ºåˆ†æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            func_name: å‡½æ•°å
            func_addr: å‡½æ•°åœ°å€
            result: åˆ†æç»“æœ
            code: æºä»£ç ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # æ¸…ç†å‡½æ•°åä¸­çš„ç‰¹æ®Šå­—ç¬¦
        safe_func_name = "".join(c for c in func_name if c.isalnum() or c in ('_', '-'))
        filename = f"{safe_func_name}_{func_addr}_{timestamp}.md"
        filepath = self.export_dir / filename
        
        content = f"""# ComprehendAI åˆ†ææŠ¥å‘Š

## å‡½æ•°ä¿¡æ¯
- **å‡½æ•°å**: {func_name}
- **åœ°å€**: {func_addr}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **ç”Ÿæˆå·¥å…·**: ComprehendAI v2.0

## åˆ†æç»“æœ

{result}

"""
        
        if code:
            content += f"""
## åç¼–è¯‘ä»£ç 

```c
{code}
```
"""
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.logger.debug(f"ç»“æœå·²å¯¼å‡ºåˆ°: {filepath}")
        return str(filepath)


class DisassemblyProcessor:
    """
    åæ±‡ç¼–ä»£ç æå–å¤„ç†å™¨
    è´Ÿè´£æå–å½“å‰å‡½æ•°åŠå…¶è°ƒç”¨çš„å­å‡½æ•°çš„åç¼–è¯‘ä»£ç 
    """
    
    def __init__(self, max_depth: int = DEFAULT_MAX_DEPTH, extract_context: bool = True):
        """
        åˆå§‹åŒ–åæ±‡ç¼–å¤„ç†å™¨
        
        Args:
            max_depth: æœ€å¤§åˆ†ææ·±åº¦,æ§åˆ¶é€’å½’æå–å­å‡½æ•°çš„å±‚æ•°
            extract_context: æ˜¯å¦æå–é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå­—ç¬¦ä¸²ã€å¸¸é‡ç­‰ï¼‰
        """
        self.logger = Logger()
        self.max_depth = max_depth
        self.extract_context = extract_context
        self._lock = Lock()
        self.context_extractor = ContextExtractor()
        self._reset_state()
        
    def _reset_state(self):
        """é‡ç½®å¤„ç†çŠ¶æ€"""
        with self._lock:
            self.processed_funcs: Set[int] = set()
            self.func_disasm_list: List[str] = []
            self.main_func_ea: Optional[int] = None
            self.failed_funcs: List[Tuple[int, str]] = []  # è®°å½•å¤±è´¥çš„å‡½æ•°
    
    def get_current_function_disasm(self, include_context: bool = True) -> Tuple[str, int]:
        """
        è·å–å½“å‰å…‰æ ‡ä½ç½®å‡½æ•°çš„åç¼–è¯‘ä»£ç åŠå…¶å­å‡½æ•°
        
        Args:
            include_context: æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            Tuple[str, int]: (åç¼–è¯‘ä»£ç å­—ç¬¦ä¸², å‡½æ•°åœ°å€)
            
        Raises:
            ValueError: æ— æ³•å®šä½å‡½æ•°èµ·å§‹åœ°å€
        """
        self._reset_state()
        start_time = time.time()
        
        current_ea = idc.get_screen_ea()
        func_start = idc.get_func_attr(current_ea, idc.FUNCATTR_START)
        
        if func_start == idaapi.BADADDR:
            error_msg = "æ— æ³•å®šä½å‡½æ•°èµ·å§‹åœ°å€ï¼Œè¯·ç¡®ä¿å…‰æ ‡ä½äºæœ‰æ•ˆå‡½æ•°å†…"
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        
        func_name = idc.get_func_name(func_start)
        self.logger.info(f"å¼€å§‹æå–å‡½æ•°ä»£ç : {func_name} ({hex(func_start)})", emoji="ğŸ“")
        self.logger.debug(f"åˆ†ææ·±åº¦: {self.max_depth}")
        
        self.main_func_ea = func_start
        
        # æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = ""
        if include_context and self.extract_context:
            self.logger.debug("æå–ä¸Šä¸‹æ–‡ä¿¡æ¯...")
            context_info = self._build_context_info(func_start)
        
        # å¤„ç†å‡½æ•°åŠå…¶å­å‡½æ•°
        self._process_function(func_start, self.max_depth)
        
        if not self.func_disasm_list:
            error_msg = "æœªèƒ½æå–åˆ°ä»»ä½•åç¼–è¯‘ä»£ç "
            self.logger.error(error_msg)
            raise ValueError(error_msg)
        
        elapsed = time.time() - start_time
        self.logger.success(
            f"ä»£ç æå–å®Œæˆ: {len(self.func_disasm_list)} ä¸ªå‡½æ•°, "
            f"è€—æ—¶ {elapsed:.2f} ç§’"
        )
        
        if self.failed_funcs:
            self.logger.warning(f"æœ‰ {len(self.failed_funcs)} ä¸ªå‡½æ•°åç¼–è¯‘å¤±è´¥")
            for ea, error in self.failed_funcs[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                self.logger.debug(f"  - {hex(ea)}: {error}")
        
        result = context_info + "\n\n" + "=" * 80 + "\n\n".join(self.func_disasm_list)
        return result, func_start
    
    def _build_context_info(self, func_ea: int) -> str:
        """
        æ„å»ºå‡½æ•°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            
        Returns:
            str: ä¸Šä¸‹æ–‡ä¿¡æ¯å­—ç¬¦ä¸²
        """
        info = self.context_extractor.get_function_info(func_ea)
        strings = self.context_extractor.extract_strings(func_ea)
        constants = self.context_extractor.extract_constants(func_ea)
        
        context = f"""
{'=' * 80}
å‡½æ•°ä¸Šä¸‹æ–‡ä¿¡æ¯
{'=' * 80}
å‡½æ•°å: {info['name']}
åœ°å€: {info['address']}
å¤§å°: {info['size']} å­—èŠ‚
"""
        
        if strings:
            context += f"\nå‘ç°çš„å­—ç¬¦ä¸² ({len(strings)} ä¸ª):\n"
            for i, s in enumerate(strings[:10], 1):  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                # æˆªæ–­è¿‡é•¿çš„å­—ç¬¦ä¸²
                display_s = s[:50] + "..." if len(s) > 50 else s
                context += f"  {i}. \"{display_s}\"\n"
            if len(strings) > 10:
                context += f"  ... è¿˜æœ‰ {len(strings) - 10} ä¸ªå­—ç¬¦ä¸²\n"
        
        if constants:
            context += f"\nå…³é”®å¸¸é‡ ({len(constants)} ä¸ª):\n  "
            context += ", ".join([hex(c) for c in constants[:15]])
            if len(constants) > 15:
                context += f" ... è¿˜æœ‰ {len(constants) - 15} ä¸ª"
            context += "\n"
        
        return context
    
    def _process_function(self, func_ea: int, depth: int):
        """
        é€’å½’å¤„ç†å‡½æ•°åŠå…¶è°ƒç”¨çš„å­å‡½æ•°
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            depth: å½“å‰å‰©ä½™é€’å½’æ·±åº¦
        """
        if func_ea in self.processed_funcs or depth < 0:
            return
            
        with self._lock:
            self.processed_funcs.add(func_ea)
        
        func_name = idc.get_func_name(func_ea)
        
        try:
            # å°è¯•åç¼–è¯‘å‡½æ•°
            self.logger.debug(f"åç¼–è¯‘: {func_name} ({hex(func_ea)}), æ·±åº¦={depth}")
            decompiled = str(idaapi.decompile(func_ea))
            
            # æ·»åŠ å‡½æ•°æ ‡è¯†ä¿¡æ¯
            header = f"\n{'=' * 80}\nå‡½æ•°: {func_name} (åœ°å€: {hex(func_ea)})\n{'=' * 80}\n"
            
            with self._lock:
                self.func_disasm_list.append(header + decompiled)
                
        except Exception as e:
            error_msg = f"åç¼–è¯‘å¤±è´¥: {str(e)}"
            self.logger.warning(f"{func_name} ({hex(func_ea)}): {error_msg}")
            with self._lock:
                self.failed_funcs.append((func_ea, error_msg))
            return
        
        # é€’å½’å¤„ç†å­å‡½æ•°
        if depth > 0:
            callees = self._get_callees(func_ea)
            if callees:
                self.logger.debug(f"{func_name} è°ƒç”¨äº† {len(callees)} ä¸ªå­å‡½æ•°")
                for callee in callees:
                    self._process_function(callee, depth - 1)
    
    def _get_callees(self, func_ea: int) -> Set[int]:
        """
        è·å–å‡½æ•°è°ƒç”¨çš„æ‰€æœ‰å­å‡½æ•°åœ°å€
        
        Args:
            func_ea: å‡½æ•°åœ°å€
            
        Returns:
            Set[int]: å­å‡½æ•°åœ°å€é›†åˆ
        """
        callees = set()
        func_end = idc.get_func_attr(func_ea, idc.FUNCATTR_END)
        
        if func_end == idaapi.BADADDR:
            return callees
            
        for ea in range(func_ea, func_end):
            for xref in idautils.XrefsFrom(ea):
                # åªå¤„ç†å‡½æ•°è°ƒç”¨ç±»å‹çš„äº¤å‰å¼•ç”¨
                if xref.type in [ida_xref.fl_CN, ida_xref.fl_CF]:
                    callee_ea = xref.to
                    # ç¡®è®¤æ˜¯å‡½æ•°èµ·å§‹åœ°å€
                    if idc.get_func_attr(callee_ea, idc.FUNCATTR_START) == callee_ea:
                        callees.add(callee_ea)
        return callees
class AIService:
    """
    AI æœåŠ¡ç±»
    è´Ÿè´£ä¸ OpenAI API äº¤äº’,å¤„ç†åˆ†æè¯·æ±‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ– AI æœåŠ¡"""
        self.config = ConfigManager()
        self.logger = Logger()
        self.stop_event = Event()
        self.last_result = ""  # ä¿å­˜æœ€åä¸€æ¬¡åˆ†æç»“æœ
        self.last_token_usage = {}  # ä¿å­˜æœ€åä¸€æ¬¡çš„ token ä½¿ç”¨æƒ…å†µ

    def ask_ai(self, prompt: str, ai_isRunning: Lock, 
              func_ea: int = 0, code: str = "", 
              use_cache: bool = True) -> Tuple[QueryStatus, str]:
        """
        å‘ AI æå‡ºé—®é¢˜
        
        Args:
            prompt: æç¤ºè¯
            ai_isRunning: è¿è¡ŒçŠ¶æ€é”
            func_ea: å‡½æ•°åœ°å€ï¼ˆç”¨äºç¼“å­˜ï¼‰
            code: ä»£ç å†…å®¹ï¼ˆç”¨äºç¼“å­˜ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            Tuple[QueryStatus, str]: (æŸ¥è¯¢çŠ¶æ€, ç»“æœæ–‡æœ¬)
        """
        messages = [{"role": "user", "content": prompt}]
        self.logger.section("ComprehendAI è¾“å‡º")
        
        self.stop_event.clear()  # åˆå§‹åŒ–åœæ­¢äº‹ä»¶
        
        try:
            result, answer = self._request_openai_with_retry(messages)
            self.last_result = answer  # ä¿å­˜ç»“æœ
            return result, answer
        except Exception as e:
            self.logger.error(f"AI è¯·æ±‚å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {str(e)}", exc_info=True)
            return QueryStatus.FAILED, ""
        finally:
            # ç¡®ä¿æ— è®ºæˆåŠŸå¤±è´¥éƒ½é‡Šæ”¾é”
            ai_isRunning.release()

    def _request_openai_with_retry(self, messages: List[dict]) -> Tuple[QueryStatus, str]:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„ OpenAI API è¯·æ±‚
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            Tuple[QueryStatus, str]: (æŸ¥è¯¢çŠ¶æ€, å›ç­”å†…å®¹)
        """
        max_retries = self.config.max_retries
        last_error = None
        
        for attempt in range(max_retries):
            try:
                return self._request_openai(messages)
            except Exception as e:
                last_error = e
                # å¦‚æœæ˜¯ç”¨æˆ·ä¸»åŠ¨åœæ­¢ï¼Œä¸é‡è¯•
                if self.stop_event.is_set():
                    return QueryStatus.STOPPED, ""
                
                if attempt < max_retries - 1:
                    delay = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    self.logger.warning(f"API è¯·æ±‚å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯• ({attempt + 1}/{max_retries}): {str(e)}")
                    time.sleep(delay)
                else:
                    self.logger.error(f"API è¯·æ±‚é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥")
        
        return QueryStatus.FAILED, ""
    
    def _request_openai(self, messages: List[dict]) -> Tuple[QueryStatus, str]:
        """
        è¯·æ±‚ OpenAI APIï¼ˆæ”¹è¿›ç‰ˆæœ¬ - æ›´å¥½çš„æµå¼è¾“å‡ºï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            Tuple[QueryStatus, str]: (æŸ¥è¯¢çŠ¶æ€, å›ç­”å†…å®¹)
        """
        reasoning_content = ""
        answer_content = ""
        is_answering = False
        start_time = time.time()
        
        try:
            self.logger.debug(f"å¼€å§‹ API è¯·æ±‚ï¼Œæ¨¡å‹: {self.config.model_name}")
            
            completion = self.config.client.chat.completions.create(
                model=self.config.model_name,
                messages=messages,
                stream=True,
            )
            
            for chunk in completion:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.stop_event.is_set():
                    self.logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¸­æ–­...", emoji="ğŸ›‘")
                    return QueryStatus.STOPPED, answer_content

                # å¤„ç† usage ä¿¡æ¯
                if not chunk.choices:
                    if hasattr(chunk, 'usage') and chunk.usage:
                        self.last_token_usage = {
                            'prompt_tokens': getattr(chunk.usage, 'prompt_tokens', 0),
                            'completion_tokens': getattr(chunk.usage, 'completion_tokens', 0),
                            'total_tokens': getattr(chunk.usage, 'total_tokens', 0)
                        }
                        self.logger.info(
                            f"Token ä½¿ç”¨: æç¤º {self.last_token_usage['prompt_tokens']}, "
                            f"å›å¤ {self.last_token_usage['completion_tokens']}, "
                            f"æ€»è®¡ {self.last_token_usage['total_tokens']}", 
                            emoji="ğŸ“Š"
                        )
                    continue
                
                delta = chunk.choices[0].delta
                
                # å¤„ç†æ¨ç†å†…å®¹(å¦‚æœæ¨¡å‹æ”¯æŒï¼Œå¦‚ o1 ç³»åˆ—)
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                    if not reasoning_content:
                        self.logger.info("=" * 20 + " æ¨ç†è¿‡ç¨‹ " + "=" * 20, emoji="ğŸ¤”")
                    print(delta.reasoning_content, end='', flush=True)
                    reasoning_content += delta.reasoning_content
                
                # å¤„ç†å›å¤å†…å®¹
                elif delta.content is not None:
                    if not is_answering and delta.content:
                        if reasoning_content:
                            print("\n")  # æ¨ç†å†…å®¹åæ¢è¡Œ
                        self.logger.info("=" * 20 + " å®Œæ•´å›å¤ " + "=" * 20, emoji="ğŸ’¡")
                        is_answering = True
                    print(delta.content, end='', flush=True)
                    answer_content += delta.content
            
            # è®¡ç®—è€—æ—¶
            elapsed_time = time.time() - start_time
            
            # æ‰“å°å®Œæ•´å›å¤ï¼ˆå¦‚æœè¿˜æ²¡æ‰“å°è¿‡ï¼‰
            if answer_content:
                if is_answering:
                    print("\n")  # ç¡®ä¿ç»“æŸæ—¶æ¢è¡Œ
                self.logger.section("åˆ†æå®Œæˆï¼")
                self.logger.info(f"è€—æ—¶: {elapsed_time:.2f} ç§’", emoji="â±ï¸")
                self.logger.debug(f"å›å¤é•¿åº¦: {len(answer_content)} å­—ç¬¦")
                return QueryStatus.SUCCESS, answer_content
            else:
                self.logger.warning("AI æœªè¿”å›æœ‰æ•ˆå†…å®¹")
                return QueryStatus.FAILED, ""
        
        except StopIteration as e:
            self.logger.info("è¿­ä»£è¢«ä¸­æ–­", emoji="â¸ï¸")
            return QueryStatus.STOPPED, answer_content

        except Exception as e:
            self.logger.error(f"API è¯·æ±‚é”™è¯¯: {str(e)}", exc_info=True)
            if hasattr(e, '__class__'):
                self.logger.debug(f"é”™è¯¯ç±»å‹: {e.__class__.__name__}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿é‡è¯•æœºåˆ¶å¤„ç†


# é»˜è®¤åˆ†ææç¤ºè¯æ¨¡æ¿
DEFAULT_ANALYSIS_PROMPT = """
ä½ æ˜¯ä¸€åäººå·¥æ™ºèƒ½é€†å‘å·¥ç¨‹ä¸“å®¶ã€‚
æˆ‘ä¼šæä¾›ä½ ä¸€äº›åæ±‡ç¼–ä»£ç ï¼Œå…¶ä¸­é¦–ä¸ªå‡½æ•°æ˜¯ä½ éœ€è¦åˆ†æå¹¶æ€»ç»“æˆæŠ¥å‘Šçš„å‡½æ•°ï¼Œ
å…¶ä½™å‡½æ•°æ˜¯è¯¥å‡½æ•°è°ƒç”¨çš„ä¸€äº›å­å‡½æ•°ã€‚

åˆ†æè¦æ±‚ï¼š
1. é‡ç‚¹æè¿°ä¸»å‡½æ•°åŠŸèƒ½ï¼Œå¹¶å¯¹æ ¸å¿ƒè¡Œä¸ºè¿›è¡Œæ¨æµ‹
2. ç®€è¦æè¿°å­å‡½æ•°åŠŸèƒ½
3. è¯†åˆ«æ½œåœ¨çš„å®‰å…¨é—®é¢˜æˆ–æ¼æ´
4. åˆ†æå‡½æ•°çš„å¤æ‚åº¦å’Œæ€§èƒ½ç‰¹ç‚¹

è¾“å‡ºè¦æ±‚ï¼š
ä¸»å‡½æ•°åŠŸèƒ½ï¼š...
æ ¸å¿ƒè¡Œä¸ºæ¨æµ‹ï¼š...
å­å‡½æ•°åŠŸèƒ½ï¼š...
å®‰å…¨æ€§åˆ†æï¼š...
å¤æ‚åº¦è¯„ä¼°ï¼š...

è¯·ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼è¾“å‡ºã€‚

ä¸‹é¢æ˜¯ä½ è¦åˆ†æçš„åæ±‡ç¼–ä»£ç ï¼š
"""


class AnalysisHandler:
    """
    åˆ†æå¤„ç†å™¨
    è´Ÿè´£åè°ƒåæ±‡ç¼–æå–å’Œ AI åˆ†æ
    """

    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå¤„ç†å™¨"""
        self.logger = Logger()
        self.disassembler = DisassemblyProcessor()
        self.ai_service = AIService()
        self.ai_isRunning = Lock()
        self.prompt = DEFAULT_ANALYSIS_PROMPT
        self.cache_manager = CacheManager()
        self.result_exporter = ResultExporter()
        self.use_cache = True  # æ˜¯å¦å¯ç”¨ç¼“å­˜
        self.auto_export = False  # æ˜¯å¦è‡ªåŠ¨å¯¼å‡ºç»“æœ
        self.last_func_ea = 0
        self.last_code = ""
        self.analysis_count = 0  # åˆ†æè®¡æ•°
        
    def set_analysis_depth(self, depth: int):
        """
        è®¾ç½®åˆ†ææ·±åº¦
        
        Args:
            depth: åˆ†ææ·±åº¦(å­å‡½æ•°é€’å½’å±‚æ•°)
        """
        if depth < 0:
            self.logger.error("åˆ†ææ·±åº¦å¿…é¡»å¤§äºç­‰äº 0")
            return
            
        self.disassembler.max_depth = depth
        self.logger.success(f"åˆ†ææ·±åº¦å·²è®¾ç½®ä¸º: {depth}")
    
    def toggle_cache(self):
        """åˆ‡æ¢ç¼“å­˜å¼€å…³"""
        self.use_cache = not self.use_cache
        status = "å¯ç”¨" if self.use_cache else "ç¦ç”¨"
        self.logger.info(f"ç¼“å­˜å·²{status}", emoji="ğŸ”§")
    
    def toggle_auto_export(self):
        """åˆ‡æ¢è‡ªåŠ¨å¯¼å‡ºå¼€å…³"""
        self.auto_export = not self.auto_export
        status = "å¯ç”¨" if self.auto_export else "ç¦ç”¨"
        self.logger.info(f"è‡ªåŠ¨å¯¼å‡ºå·²{status}", emoji="ğŸ”§")
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache_manager.clear()
    
    def show_cache_stats(self):
        """æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.cache_manager.get_stats()
        self.logger.section("ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
        self.logger.info(f"ç¼“å­˜æ¡ç›®æ•°: {stats['count']}/{stats['max_size']}")
        self.logger.info(f"æ€»å¤§å°: {stats['total_size_kb']:.2f} KB")
    
    def show_stats(self):
        """æ˜¾ç¤ºæ’ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.section("ComprehendAI ç»Ÿè®¡ä¿¡æ¯")
        self.logger.info(f"æ€»åˆ†ææ¬¡æ•°: {self.analysis_count}")
        self.logger.info(f"ç¼“å­˜çŠ¶æ€: {'å¯ç”¨' if self.use_cache else 'ç¦ç”¨'}")
        self.logger.info(f"è‡ªåŠ¨å¯¼å‡º: {'å¯ç”¨' if self.auto_export else 'ç¦ç”¨'}")
        self.logger.info(f"åˆ†ææ·±åº¦: {self.disassembler.max_depth}")
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        cache_stats = self.cache_manager.get_stats()
        self.logger.info(f"ç¼“å­˜æ¡ç›®: {cache_stats['count']}/{cache_stats['max_size']}")
        
        # æ˜¾ç¤º token ä½¿ç”¨æƒ…å†µ
        if self.ai_service.last_token_usage:
            self.logger.info(f"ä¸Šæ¬¡ Token ä½¿ç”¨: {self.ai_service.last_token_usage['total_tokens']}")
    
    def export_last_result(self):
        """å¯¼å‡ºä¸Šæ¬¡åˆ†æç»“æœ"""
        if not self.ai_service.last_result:
            self.logger.error("æ²¡æœ‰å¯å¯¼å‡ºçš„ç»“æœ")
            return
        
        func_name = idc.get_func_name(self.last_func_ea) or "unknown"
        func_addr = hex(self.last_func_ea) if self.last_func_ea else "0x0"
        
        filepath = self.result_exporter.export_result(
            func_name, func_addr, 
            self.ai_service.last_result,
            self.last_code
        )
        
        if filepath:
            self.logger.success(f"ç»“æœå·²å¯¼å‡ºåˆ°: {filepath}")
    
    def _create_analysis_prompt(self, disassembly: str, template: str = None) -> str:
        """
        åˆ›å»ºåˆ†ææç¤ºè¯
        
        Args:
            disassembly: åæ±‡ç¼–ä»£ç 
            template: æç¤ºè¯æ¨¡æ¿ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: å®Œæ•´æç¤ºè¯
        """
        if template:
            return template + "\n" + disassembly
        return self.prompt + "\n" + disassembly
    
    def _create_custom_query_with_code(self, disassembly: str, question: str) -> str:
        """
        åˆ›å»ºå¸¦ä»£ç çš„è‡ªå®šä¹‰æŸ¥è¯¢
        
        Args:
            disassembly: åæ±‡ç¼–ä»£ç 
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: å®Œæ•´æç¤ºè¯
        """
        return f"{question}\n\nåæ±‡ç¼–ä»£ç :\n{disassembly}"
    
    def create_ai_task(self, task_type: TaskType, question: str = "", template_name: str = ""):
        """
        åˆ›å»º AI åˆ†æä»»åŠ¡
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            question: ç”¨æˆ·é—®é¢˜(ä»…éƒ¨åˆ†ä»»åŠ¡ç±»å‹éœ€è¦)
            template_name: æ¨¡æ¿åç§°(ä»…éƒ¨åˆ†ä»»åŠ¡ç±»å‹éœ€è¦)
        """
        try:
            self.logger.debug(f"åˆ›å»ºä»»åŠ¡: {task_type.name}")
            
            match task_type:
                case TaskType.ANALYSIS:
                    self._handle_analysis(template_name)
                    
                case TaskType.CUSTOM_QUERY:
                    if not question:
                        self.logger.error("è¯·æä¾›é—®é¢˜å†…å®¹")
                        return
                    self._async_task(question, 0, "")
                    
                case TaskType.CUSTOM_QUERY_WITH_CODE:
                    if not question:
                        self.logger.error("è¯·æä¾›é—®é¢˜å†…å®¹")
                        return
                    self.logger.info("æ­£åœ¨æå–åæ±‡ç¼–ä»£ç ...", emoji="ğŸ“")
                    disassembly, func_ea = self.disassembler.get_current_function_disasm()
                    self.last_func_ea = func_ea
                    self.last_code = disassembly
                    prompt = self._create_custom_query_with_code(disassembly, question)
                    self._async_task(prompt, func_ea, disassembly)
                
                case TaskType.SECURITY_AUDIT:
                    self._handle_analysis("SECURITY_AUDIT")
                
                case TaskType.VULNERABILITY_SCAN:
                    self._handle_analysis("VULNERABILITY_SCAN")
                    
        except ValueError as e:
            self.logger.error(str(e))
        except Exception as e:
            self.logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}", exc_info=True)
    
    def _handle_analysis(self, template_name: str = ""):
        """
        å¤„ç†ä»£ç åˆ†æä»»åŠ¡
        
        Args:
            template_name: æ¨¡æ¿åç§°
        """
        try:
            disassembly, func_ea = self.disassembler.get_current_function_disasm()
            self.last_func_ea = func_ea
            self.last_code = disassembly
            
            # æ£€æŸ¥ç¼“å­˜
            if self.use_cache:
                cached_result = self.cache_manager.get(func_ea, disassembly)
                if cached_result:
                    # ç›´æ¥è¾“å‡ºç¼“å­˜ç»“æœ
                    self.logger.section("ç¼“å­˜çš„åˆ†æç»“æœ")
                    print(cached_result)
                    self.ai_service.last_result = cached_result
                    
                    if self.auto_export:
                        self.export_last_result()
                    
                    return
            
            # åˆ›å»ºæç¤ºè¯
            if template_name:
                template = PromptTemplates.get_template(template_name)
                prompt = self._create_analysis_prompt(disassembly, template)
            else:
                prompt = self._create_analysis_prompt(disassembly)
            
            # æ‰§è¡Œåˆ†æ
            self._async_task(prompt, func_ea, disassembly)
        except Exception as e:
            self.logger.error(f"åˆ†æä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
        
    def _async_task(self, prompt: str, func_ea: int = 0, code: str = ""):
        """
        å¼‚æ­¥æ‰§è¡Œ AI ä»»åŠ¡
        
        Args:
            prompt: æç¤ºè¯
            func_ea: å‡½æ•°åœ°å€
            code: ä»£ç å†…å®¹
        """
        if self.ai_isRunning.acquire(blocking=False):
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ AI è¯·æ±‚
            task = Thread(
                target=self._run_ai_task,
                args=(prompt, func_ea, code),
                daemon=True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
            )
            task.start()
            self.logger.info("AI ä»»åŠ¡å·²å¯åŠ¨...", emoji="ğŸš€")
        else:
            self.logger.error("å½“å‰ AI æ­£åœ¨å¤„ç†ä»»åŠ¡ï¼Œè¯·ç¨åå°è¯•æˆ–ä½¿ç”¨ Stop åœæ­¢å½“å‰ä»»åŠ¡")
    
    def _run_ai_task(self, prompt: str, func_ea: int, code: str):
        """
        è¿è¡Œ AI ä»»åŠ¡å¹¶å¤„ç†ç»“æœ
        
        Args:
            prompt: æç¤ºè¯
            func_ea: å‡½æ•°åœ°å€
            code: ä»£ç å†…å®¹
        """
        try:
            status, result = self.ai_service.ask_ai(
                prompt, 
                self.ai_isRunning,
                func_ea,
                code,
                self.use_cache
            )
            
            # æ›´æ–°ç»Ÿè®¡
            if status == QueryStatus.SUCCESS:
                self.analysis_count += 1
            
            # ä¿å­˜åˆ°ç¼“å­˜
            if status == QueryStatus.SUCCESS and result and func_ea and self.use_cache:
                self.cache_manager.set(func_ea, code, result)
            
            # è‡ªåŠ¨å¯¼å‡º
            if status == QueryStatus.SUCCESS and result and self.auto_export:
                self.export_last_result()
        except Exception as e:
            self.logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
    
    def stop(self):
        """åœæ­¢å½“å‰ AI ä»»åŠ¡"""
        if self.ai_service.stop_event.is_set():
            self.logger.info("æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡", emoji="â„¹ï¸")
        else:
            self.ai_service.stop_event.set()
            self.logger.info("æ­£åœ¨åœæ­¢ä»»åŠ¡...", emoji="ğŸ›‘")
    
    def choose_template(self) -> Optional[str]:
        """
        è®©ç”¨æˆ·é€‰æ‹©æç¤ºè¯æ¨¡æ¿
        
        Returns:
            Optional[str]: é€‰æ‹©çš„æ¨¡æ¿åç§°
        """
        templates = {
            "1": ("æ ‡å‡†åˆ†æ", "STANDARD_ANALYSIS"),
            "2": ("å®‰å…¨å®¡è®¡", "SECURITY_AUDIT"),
            "3": ("æ¼æ´æ‰«æ", "VULNERABILITY_SCAN"),
            "4": ("ç®—æ³•è¯†åˆ«", "ALGORITHM_RECOGNITION"),
            "5": ("å¿«é€Ÿæ€»ç»“", "QUICK_SUMMARY"),
        }
        
        self.logger.info("\nå¯ç”¨æ¨¡æ¿:")
        for key, (name, _) in templates.items():
            self.logger.info(f"{key}. {name}")
        
        choice = idaapi.ask_str("1", 0, "é€‰æ‹©æ¨¡æ¿ (è¾“å…¥æ•°å­—):")
        if choice and choice in templates:
            self.logger.debug(f"ç”¨æˆ·é€‰æ‹©æ¨¡æ¿: {templates[choice][0]}")
            return templates[choice][1]
        
        return None

class ComprehendAIPlugin(idaapi.plugin_t):
    """
    ComprehendAI IDA Pro æ’ä»¶
    æä¾›åŸºäº AI çš„æ™ºèƒ½äºŒè¿›åˆ¶ä»£ç åˆ†æåŠŸèƒ½
    """
    
    flags = idaapi.PLUGIN_HIDE
    comment = "AI-based Reverse Analysis Plugin"
    help = "Perform AI-based analysis on binary code using OpenAI"
    wanted_name = "ComprehendAI"
    wanted_hotkey = "Ctrl+Shift+A"

    # æ’ä»¶åŠ¨ä½œå®šä¹‰ (action_id, æ˜¾ç¤ºåç§°, æç¤ºä¿¡æ¯)
    ACTION_DEFINITIONS = [
        # åŸºç¡€åˆ†æ
        ("AI_analysis:Analysis", "ğŸ¤– AI æ™ºèƒ½åˆ†æ", "æ‰§è¡Œæ ‡å‡†AIä»£ç åˆ†æ"),
        ("AI_analysis:SecurityAudit", "ğŸ”’ å®‰å…¨å®¡è®¡", "æ·±åº¦å®‰å…¨æ¼æ´å®¡è®¡"),
        ("AI_analysis:VulnerabilityScan", "ğŸ› æ¼æ´æ‰«æ", "æ‰«ææ½œåœ¨å®‰å…¨æ¼æ´"),
        ("AI_analysis:AlgorithmRecognition", "ğŸ” ç®—æ³•è¯†åˆ«", "è¯†åˆ«åŠ å¯†å’Œç®—æ³•"),
        ("AI_analysis:QuickSummary", "âš¡ å¿«é€Ÿæ€»ç»“", "å¿«é€Ÿæ€»ç»“å‡½æ•°åŠŸèƒ½"),
        
        # è‡ªå®šä¹‰æŸ¥è¯¢
        ("AI_analysis:CustomQueryWithCode", "ğŸ’¬ å¸¦ä»£ç æé—®", "ç»“åˆå½“å‰ä»£ç å‘AIæé—®"),
        ("AI_analysis:CustomQuery", "ğŸ’­ ç›´æ¥æé—®", "ç›´æ¥å‘AIæé—®"),
        
        # ç»“æœç®¡ç†
        ("AI_analysis:ExportResult", "ğŸ’¾ å¯¼å‡ºç»“æœ", "å¯¼å‡ºä¸Šæ¬¡åˆ†æç»“æœ"),
        ("AI_analysis:ToggleAutoExport", "ğŸ“¤ è‡ªåŠ¨å¯¼å‡º", "åˆ‡æ¢è‡ªåŠ¨å¯¼å‡ºå¼€å…³"),
        
        # ç¼“å­˜ç®¡ç†
        ("AI_analysis:ToggleCache", "ğŸ”„ åˆ‡æ¢ç¼“å­˜", "å¯ç”¨/ç¦ç”¨ç»“æœç¼“å­˜"),
        ("AI_analysis:ClearCache", "ğŸ—‘ï¸ æ¸…ç©ºç¼“å­˜", "æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®"),
        ("AI_analysis:ShowCacheStats", "ğŸ“Š ç¼“å­˜ç»Ÿè®¡", "æŸ¥çœ‹ç¼“å­˜ä½¿ç”¨ç»Ÿè®¡"),
        
        # é…ç½®
        ("AI_analysis:SetDepth", "âš™ï¸ åˆ†ææ·±åº¦", "è®¾ç½®å‡½æ•°åˆ†æé€’å½’æ·±åº¦"),
        ("AI_analysis:SetPrompt", "ğŸ“ è‡ªå®šä¹‰æç¤ºè¯", "è‡ªå®šä¹‰åˆ†ææç¤ºè¯æ¨¡æ¿"),
        
        # ä¿¡æ¯ä¸æ§åˆ¶
        ("AI_analysis:ShowStats", "ğŸ“ˆ æ’ä»¶ç»Ÿè®¡", "æŸ¥çœ‹æ’ä»¶ä½¿ç”¨ç»Ÿè®¡"),
        ("AI_analysis:Stop", "ğŸ›‘ åœæ­¢", "åœæ­¢å½“å‰AIä»»åŠ¡"),
    ]

    def init(self):
        """
        åˆå§‹åŒ–æ’ä»¶
        
        Returns:
            int: PLUGIN_KEEP ä¿æŒæ’ä»¶åŠ è½½
        """
        try:
            # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
            self.logger = Logger()
            
            # æ³¨å†Œ UI é’©å­
            self.ui_hook = self.MenuHook()
            self.ui_hook.hook()
            
            # åˆ›å»ºåˆ†æå¤„ç†å™¨
            self.handler = AnalysisHandler()
            
            # æ³¨å†Œæ‰€æœ‰åŠ¨ä½œ
            self._register_actions()
            
            self.logger.section("ComprehendAI æ’ä»¶å·²æˆåŠŸåŠ è½½")
            self.logger.info(f"ç‰ˆæœ¬: ä¼˜åŒ–ç‰ˆ v2.0")
            self.logger.info(f"å·²æ³¨å†Œ {len(self.ACTION_DEFINITIONS)} ä¸ªåŠ¨ä½œ")
            
            return idaapi.PLUGIN_KEEP
            
        except Exception as e:
            logger = Logger()
            logger.section("ComprehendAI æ’ä»¶åˆå§‹åŒ–å¤±è´¥")
            logger.error(str(e), exc_info=True)
            return idaapi.PLUGIN_SKIP

    def run(self, arg):
        """
        è¿è¡Œæ’ä»¶(å½“å‰æœªä½¿ç”¨)
        
        Args:
            arg: æ’ä»¶å‚æ•°
        """
        pass

    def term(self):
        """å¸è½½æ’ä»¶"""
        try:
            self.ui_hook.unhook()
            self._unregister_actions()
            self.logger.section("ComprehendAI æ’ä»¶å·²å¸è½½")
        except Exception as e:
            self.logger.error(f"æ’ä»¶å¸è½½æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)

    def _register_actions(self):
        """æ³¨å†Œæ‰€æœ‰èœå•åŠ¨ä½œ"""
        success_count = 0
        for action_id, label, tooltip in self.ACTION_DEFINITIONS:
            action_desc = idaapi.action_desc_t(
                action_id,
                label,
                self.MenuCommandHandler(action_id, self.handler),
                None,
                tooltip,
                0
            )
            if idaapi.register_action(action_desc):
                success_count += 1
            else:
                self.logger.warning(f"æ³¨å†ŒåŠ¨ä½œå¤±è´¥: {action_id}")
        
        self.logger.debug(f"æˆåŠŸæ³¨å†Œ {success_count}/{len(self.ACTION_DEFINITIONS)} ä¸ªåŠ¨ä½œ")

    def _unregister_actions(self):
        """æ³¨é”€æ‰€æœ‰èœå•åŠ¨ä½œ"""
        for action_id, _, _ in self.ACTION_DEFINITIONS:
            idaapi.unregister_action(action_id)

    class MenuHook(UI_Hooks):
        """èœå•é’©å­,ç”¨äºåœ¨å³é”®èœå•ä¸­æ·»åŠ æ’ä»¶é€‰é¡¹"""
        
        def finish_populating_widget_popup(self, form, popup):
            """
            åœ¨çª—å£å¼¹å‡ºèœå•å®Œæˆå¡«å……æ—¶è°ƒç”¨
            
            Args:
                form: çª—å£å¥æŸ„
                popup: å¼¹å‡ºèœå•å¥æŸ„
            """
            widget_type = idaapi.get_widget_type(form)
            
            # åªåœ¨åæ±‡ç¼–è§†å›¾å’Œä¼ªä»£ç è§†å›¾ä¸­æ˜¾ç¤ºèœå•
            if widget_type in (idaapi.BWN_DISASM, idaapi.BWN_PSEUDOCODE):
                for action_id, _, _ in ComprehendAIPlugin.ACTION_DEFINITIONS:
                    idaapi.attach_action_to_popup(
                        form, 
                        popup, 
                        action_id, 
                        "ComprehendAI/", 
                        idaapi.SETMENU_APP
                    )

    class MenuCommandHandler(action_handler_t):
        """èœå•å‘½ä»¤å¤„ç†å™¨"""
        
        def __init__(self, action_id: str, handler: AnalysisHandler):
            """
            åˆå§‹åŒ–å‘½ä»¤å¤„ç†å™¨
            
            Args:
                action_id: åŠ¨ä½œ ID
                handler: åˆ†æå¤„ç†å™¨
            """
            super().__init__()
            self.action_id = action_id
            self.handler = handler
    
        def activate(self, ctx):
            """
            æ¿€æ´»åŠ¨ä½œ
            
            Args:
                ctx: ä¸Šä¸‹æ–‡
                
            Returns:
                int: 1 è¡¨ç¤ºæˆåŠŸ
            """
            try:
                match self.action_id:
                    # åŸºç¡€åˆ†æåŠŸèƒ½
                    case "AI_analysis:Analysis":
                        self.handler.create_ai_task(TaskType.ANALYSIS)
                    
                    case "AI_analysis:SecurityAudit":
                        self.handler.create_ai_task(TaskType.SECURITY_AUDIT)
                    
                    case "AI_analysis:VulnerabilityScan":
                        self.handler.create_ai_task(TaskType.VULNERABILITY_SCAN)
                    
                    case "AI_analysis:AlgorithmRecognition":
                        self.handler.create_ai_task(TaskType.ANALYSIS, template_name="ALGORITHM_RECOGNITION")
                    
                    case "AI_analysis:QuickSummary":
                        self.handler.create_ai_task(TaskType.ANALYSIS, template_name="QUICK_SUMMARY")
                    
                    # è‡ªå®šä¹‰æŸ¥è¯¢
                    case "AI_analysis:CustomQuery":
                        question = idaapi.ask_text(0, "", "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:")
                        if question:
                            self.handler.create_ai_task(TaskType.CUSTOM_QUERY, question)
                    
                    case "AI_analysis:CustomQueryWithCode":
                        question = idaapi.ask_text(
                            0, 
                            "", 
                            "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ (å°†ç»“åˆå½“å‰ä»£ç ):"
                        )
                        if question:
                            self.handler.create_ai_task(
                                TaskType.CUSTOM_QUERY_WITH_CODE, 
                                question
                            )
                    
                    # ç»“æœç®¡ç†
                    case "AI_analysis:ExportResult":
                        self.handler.export_last_result()
                    
                    case "AI_analysis:ToggleAutoExport":
                        self.handler.toggle_auto_export()
                    
                    # ç¼“å­˜ç®¡ç†
                    case "AI_analysis:ToggleCache":
                        self.handler.toggle_cache()
                    
                    case "AI_analysis:ClearCache":
                        if idaapi.ask_yn(1, "ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰ç¼“å­˜å—ï¼Ÿ") == 1:
                            self.handler.clear_cache()
                    
                    case "AI_analysis:ShowCacheStats":
                        self.handler.show_cache_stats()
                    
                    # é…ç½®
                    case "AI_analysis:SetDepth":
                        current_depth = self.handler.disassembler.max_depth
                        new_depth = idaapi.ask_long(
                            current_depth, 
                            f"è®¾ç½®åˆ†ææ·±åº¦ (å½“å‰: {current_depth}):"
                        )
                        if new_depth is not None:
                            self.handler.set_analysis_depth(new_depth)
                    
                    case "AI_analysis:SetPrompt":
                        new_prompt = idaapi.ask_text(
                            0, 
                            self.handler.prompt, 
                            "è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿:"
                        )
                        if new_prompt:
                            self.handler.prompt = new_prompt
                            self.handler.logger.success("æç¤ºè¯æ¨¡æ¿å·²æ›´æ–°")
                    
                    # ä¿¡æ¯ä¸æ§åˆ¶
                    case "AI_analysis:ShowStats":
                        self.handler.show_stats()
                    
                    case "AI_analysis:Stop":
                        self.handler.stop()
                        
            except Exception as e:
                Logger().error(f"æ‰§è¡Œæ“ä½œå¤±è´¥: {str(e)}", exc_info=True)
                
            return 1

        def update(self, ctx):
            """
            æ›´æ–°åŠ¨ä½œçŠ¶æ€
            
            Args:
                ctx: ä¸Šä¸‹æ–‡
                
            Returns:
                int: åŠ¨ä½œçŠ¶æ€
            """
            return idaapi.AST_ENABLE_ALWAYS


def PLUGIN_ENTRY():
    """
    IDA Pro æ’ä»¶å…¥å£ç‚¹
    
    Returns:
        ComprehendAIPlugin: æ’ä»¶å®ä¾‹
    """
    return ComprehendAIPlugin()